{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot pentru răspunderea la întrebări frecvente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalarea bibliotecilor necesare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daca nu sunt deja instalate\n",
    "# altfel se comenteaza\n",
    "# %pip install numpy\n",
    "# %pip install scikit-learn\n",
    "# %pip install scipy\n",
    "# %pip install nltk\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install spacy\n",
    "# %pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelucrarea datelor\n",
    "\n",
    "1. Setul de date\n",
    "\n",
    "Setul de date prevede mai multe coloane pentru a oferi o prespectivă mai largă pentru înțelegerea acestuia.\n",
    "\n",
    "În cazul de față de interese sunt coloanele „Question” și „Answer”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ArticleTitle', 'Question', 'Answer', 'DifficultyFromQuestioner',\n",
      "       'DifficultyFromAnswerer', 'ArticleFile'],\n",
      "      dtype='object')\n",
      "                                               Question  \\\n",
      "0     Was Abraham Lincoln the sixteenth President of...   \n",
      "1     Was Abraham Lincoln the sixteenth President of...   \n",
      "2     Did Lincoln sign the National Banking Act of 1...   \n",
      "3     Did Lincoln sign the National Banking Act of 1...   \n",
      "4                      Did his mother die of pneumonia?   \n",
      "...                                                 ...   \n",
      "3992          What areas do the Grevy's Zebras inhabit?   \n",
      "3994  Which species of zebra is known as the common ...   \n",
      "3995  Which species of zebra is known as the common ...   \n",
      "3996                     At what age can a zebra breed?   \n",
      "3997                     At what age can a zebra breed?   \n",
      "\n",
      "                                                 Answer  \n",
      "0                                                   yes  \n",
      "1                                                  Yes.  \n",
      "2                                                   yes  \n",
      "3                                                  Yes.  \n",
      "4                                                    no  \n",
      "...                                                 ...  \n",
      "3992  semi-arid grasslands of Ethiopia and northern ...  \n",
      "3994  Plains Zebra (Equus quagga, formerly Equus bur...  \n",
      "3995                                       Plains Zebra  \n",
      "3996                                        five or six  \n",
      "3997                                             5 or 6  \n",
      "\n",
      "[3420 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"all_questions.txt\", sep=\"\\t\")\n",
    "df.head()\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "data = df[['Question', 'Answer']].dropna()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prelucrarea textului\n",
    "\n",
    "Constă în:\n",
    "* eliminarea duplicatelor,\n",
    "* transformarea din uppercase în lowercase,\n",
    "* eliminarea caracterelor care nu sunt cuvinte și care nu sunt whitespace-uri\n",
    "* eliminarea cifrelor din text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:2203\n",
      "Text curatat:\n",
      "0       [abraham, lincoln, sixteenth, president, unite...\n",
      "2                 [lincoln, sign, national, banking, act]\n",
      "4                                [mother, die, pneumonia]\n",
      "6                [many, long, lincoln, formal, education]\n",
      "8                     [lincoln, begin, political, career]\n",
      "                              ...                        \n",
      "3988                                         [zebra, eat]\n",
      "3990                                        [zebra, hunt]\n",
      "3992                       [area, grevys, zebra, inhabit]\n",
      "3994                 [specie, zebra, know, common, zebra]\n",
      "3996                                  [age, zebra, breed]\n",
      "Name: Question, Length: 2148, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# eliminare duplicate\n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].drop_duplicates(keep=\"first\")\n",
    "\n",
    "print(f\"Train:{len(data)}\")\n",
    "\n",
    "# transformare din uppercase in lowercase\n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "# eliminare a caracterelor care nu sunt cuvinte si care nu sunt whitespace-uri\n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "\n",
    "# eliminare cifre din text \n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].replace(to_replace=r'\\d', value='', regex=True)\n",
    "\n",
    "data = data.dropna(subset=[\"Question\"])\n",
    "\n",
    "print(f\"Text curatat:\")\n",
    "print(data[\"Question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Curatarea textului - Lemmatizarea textului\n",
    "\n",
    "Lemmatizarea presupune eliminarea eventoalelor constructii sufixate sau prefixate pentru a aduce cuvântul la forma lui de bază.\n",
    "\n",
    "Scopul utilizării este:\n",
    "\n",
    "- uniformizare, cuvintele cu acceași rădăcină sunt tratate ca echivalente;\n",
    "- reducerea dimensionalității;\n",
    "- îmbunătățirea căutării/ comparării."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Prelucrat\n",
      "0       [abraham, lincoln, sixteenth, president, unite...\n",
      "2                 [lincoln, sign, national, banking, act]\n",
      "4                                [mother, die, pneumonia]\n",
      "6               [many, long, lincolns, formal, education]\n",
      "8                     [lincoln, begin, political, career]\n",
      "                              ...                        \n",
      "3988                                        [zebras, eat]\n",
      "3990                                     [zebras, hunted]\n",
      "3992                     [areas, grevys, zebras, inhabit]\n",
      "3994               [species, zebra, known, common, zebra]\n",
      "3996                                  [age, zebra, breed]\n",
      "Name: Question, Length: 2203, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# tokenizare\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].apply(lambda x: tokenizer.tokenize(x) if isinstance(x, str) else x)\n",
    "\n",
    "# stergere stopwords\n",
    "\n",
    "# poate necesita decomentare\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "print(\"Text Prelucrat\")\n",
    "print(data[\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text dupa Lemmatizare:\n",
      "0       [abraham, lincoln, sixteenth, president, unite...\n",
      "2                 [lincoln, sign, national, banking, act]\n",
      "4                                [mother, die, pneumonia]\n",
      "6                [many, long, lincoln, formal, education]\n",
      "8                     [lincoln, begin, political, career]\n",
      "                              ...                        \n",
      "3988                                         [zebra, eat]\n",
      "3990                                        [zebra, hunt]\n",
      "3992                       [area, grevys, zebra, inhabit]\n",
      "3994                 [specie, zebra, know, common, zebra]\n",
      "3996                                  [age, zebra, breed]\n",
      "Name: Question, Length: 2203, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# pot necesita sa fie decomentate\n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# lemmatizare\n",
    "# initializare lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# functie pentru lemmatizare token-uri\n",
    "def lemmatize_tokens(tokens):\n",
    "    # conversie din pos in wordnet\n",
    "    def get_wordnet_pos(word):\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    # lematizare token-uri\n",
    "    lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    \n",
    "    # returnare ca o lista\n",
    "    return lemmas\n",
    "\n",
    "data[\"Question\"] = data[\"Question\"].apply(lemmatize_tokens)\n",
    "\n",
    "print(\"Text dupa Lemmatizare:\")\n",
    "print(data[\"Question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Word Embedding\n",
    "\n",
    "Word Embeddings sunt reprezentări numerice ale cuvintelor într-un spațiu dimensional mai mic pentru a capta informația semantică și sintactică.\n",
    "\n",
    "Word Embedding este o abordare pentru reprezentarea cuvintelor și a documentelor.\n",
    "Word Embedding sau Word Vector este un vector numeric pentru a reprezenta un cuvânt într-un spațiu dimensional mai mic.\n",
    "\n",
    "În cazul de față am ales o abordare bazată pe Contextualized Word Embeddings, mai precis BERT.\n",
    "\n",
    "BERT este un model transformer care învață încorporări contextuale pentru cuvinte. Consideră întregul context al unui cuvânt ceea ce oferă o informație contextuală mai bogată decât dacă se folosesc frequency based embeddings, TF-IDF, sau prediction based word embedding, Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00719016  0.0577301  -0.01099544 ... -0.01460441 -0.05865231\n",
      "   0.02819466]\n",
      " [-0.00987572 -0.01382468 -0.09109937 ... -0.02423994 -0.04201196\n",
      "  -0.01090215]\n",
      " [ 0.00048814 -0.00686363  0.0077758  ... -0.05062495  0.09680961\n",
      "   0.00913441]\n",
      " ...\n",
      " [-0.04268538  0.03998202 -0.02327148 ...  0.04347909  0.05327745\n",
      "   0.00329734]\n",
      " [-0.09858818  0.02357402 -0.02428912 ...  0.04131453  0.07671772\n",
      "   0.01495439]\n",
      " [-0.10551791  0.09273266 -0.00291227 ...  0.0076475   0.1136751\n",
      "  -0.00361189]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# reconstruire intrebari ca string\n",
    "data[\"QuestionText\"] = data[\"Question\"].apply(lambda tokens: \" \".join(tokens))\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "questions = data[\"QuestionText\"].tolist()\n",
    "answers = data[\"Answer\"].tolist()\n",
    "question_embeddings = model.encode(questions, convert_to_numpy=True)\n",
    "\n",
    "print(question_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calcularea gradului similaritatii\n",
    "\n",
    "Se testează mai multe funcții pentru similaritate mai bună pentru întrebări\n",
    "\n",
    "- cosine_similarity\n",
    "\n",
    "$$\n",
    "\\mathrm{sim(X, Y)} = \\frac{\\sum_{i = 1}^{k} X_i * Y_i}{\\sqrt{\\sum_{i = 1}^{k} X_i^2} \\sqrt{\\sum_{i = 1}^{k} Y_i^2}}\n",
    "$$\n",
    "\n",
    "Cosine_similarity măsoară cosinusul unghiului dintre doi vectori în spațiu. În cazul prelucării de texx, este o metrică care nu este afectată de frecvența cuvintelor care apar în documente și este eficientă pentru a compara documente de diferite dimensiuni.\n",
    "\n",
    "Este o metrică care nu este afectată de lungimea textului. Textele asimetrice pot avea un unghi mai mic între ele. Cu cât unghiul este mai mic cu atât similaritatea este mai mare. De asemenea, cosinusul are domeniul cuprins între `[-1, 1]`, iar din perspectiva NLP-urilor, valorile sunt cuprinse între `[0, 1]`. Dacă un cuvânt nu apare, atunci fracția devine 0.\n",
    "\n",
    "- distanta euclidiana\n",
    "\n",
    "$$\n",
    "\\mathrm{sim(X, Y) = \\frac{1}{1 + \\sqrt{\\sum_{i = 1}^{k} (X_i - Y_i)^2}}}\n",
    "$$\n",
    "\n",
    "Distanța euclidiană reprezintă lungimea unui segment de dreaptă dintre două puncte. În cazul NLP-urilor, aceste puncte reprezintă cuvinte.\n",
    "\n",
    "Cu cât distanța dintre două texte este mai mică, cu atât mai similare sunt acestea. Principala problemă cu această metrică este că lungimea textului afectează rezultatul. Propozițiile mai lungi tind să aibă un scor mai mare comparativ cu cele mai scurte.\n",
    "\n",
    "- produsul scalar\n",
    "\n",
    "$$\n",
    "\\mathrm{sim(X, Y) = \\sum_{i = 1}^{k} X_i * Y_i}\n",
    "$$\n",
    "\n",
    "Produsul scalar este o măsură de proiecție și intuitiv arată cam cât de mult un vector este orientat în direcția celuilalt.\n",
    "\n",
    "Va avea valori mari dacă vectorii au direcții similare și au o lungime mai mare.\n",
    "\n",
    "O problemă care apare, la fel ca în cazul distanței euclidiene, este că depinde de lungimea vectorilor. De aceea produsul scalar nu este recomandat decât dacă s-a aplicat normalizarea pe respectivii vectori, caz în care, produsul scalar este totuna cu cosine_similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# inversul funcțiilor pentru a crește cu similaritatea\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return (prod_scal(a, b) / (norm(a) * norm(b)))\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return 1 / (1 + np.sqrt(prod_scal(a - b, a - b)))\n",
    "\n",
    "def prod_scal(A, B):\n",
    "    return (sum(a * b for a, b in zip(A, B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Funcție best_match pentru o întrebare scrisă de utilizator și dicționarul de întrebări\n",
    "\n",
    "Trebuiesc făcute exact aceleași operații de prelucrare și curățare de text așa cum au fost făcute pentru întrebările din setul de date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def best_match(u_question, method=\"cosine\"):\n",
    "\n",
    "    sim_func = {\n",
    "        \"cosine\": cosine_sim,\n",
    "        \"euclidean\": euclidean_distance,\n",
    "        \"prodscal\": prod_scal\n",
    "    }.get(method)\n",
    "\n",
    "    text = u_question.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    tokens = lemmatize_tokens(tokens)\n",
    "    clean_text = \" \".join(tokens)\n",
    "\n",
    "    u_vec = model.encode(clean_text)\n",
    "\n",
    "    scores = [sim_func(u_vec, q_vec) for q_vec in question_embeddings]\n",
    "    idx = int(np.argmax(scores))\n",
    "\n",
    "    return {\n",
    "        \"Input\": u_question,\n",
    "        \"Matched Question\": questions[idx],\n",
    "        \"Answer\": answers[idx],\n",
    "        \"Score\": float(scores[idx]),\n",
    "        \"Method\": method\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Input': 'How old is Abraham Lincoln?', 'Matched Question': 'old lincoln', 'Answer': 'seven', 'Score': 0.9362112283706665, 'Method': 'cosine'}\n",
      "{'Input': 'How old is Abraham Lincoln?', 'Matched Question': 'old lincoln', 'Answer': 'seven', 'Score': 0.7368225455284119, 'Method': 'euclidean'}\n",
      "{'Input': 'How old is Abraham Lincoln?', 'Matched Question': 'old lincoln', 'Answer': 'seven', 'Score': 0.9362112283706665, 'Method': 'prodscal'}\n",
      "{'Input': 'Did Canada help UN peacekeeping?', 'Matched Question': 'canada help un peacekeeping effort', 'Answer': 'During the Suez Crisis of 1956, Lester B. Pearson eased tensions by proposing the inception of the United Nations Peacekeeping Force. Canada has since served in 50 peacekeeping missions, including every UN peacekeeping effort until 1989', 'Score': 0.9868934154510498, 'Method': 'cosine'}\n",
      "{'Input': 'Did Canada help UN peacekeeping?', 'Matched Question': 'canada help un peacekeeping effort', 'Answer': 'During the Suez Crisis of 1956, Lester B. Pearson eased tensions by proposing the inception of the United Nations Peacekeeping Force. Canada has since served in 50 peacekeeping missions, including every UN peacekeeping effort until 1989', 'Score': 0.8606553673744202, 'Method': 'euclidean'}\n",
      "{'Input': 'Did Canada help UN peacekeeping?', 'Matched Question': 'canada help un peacekeeping effort', 'Answer': 'During the Suez Crisis of 1956, Lester B. Pearson eased tensions by proposing the inception of the United Nations Peacekeeping Force. Canada has since served in 50 peacekeeping missions, including every UN peacekeeping effort until 1989', 'Score': 0.986893355846405, 'Method': 'prodscal'}\n"
     ]
    }
   ],
   "source": [
    "# How old was Lincoln in 1816? seven\n",
    "\n",
    "print(best_match(\"How old is Abraham Lincoln?\", method=\"cosine\"))\n",
    "print(best_match(\"How old is Abraham Lincoln?\", method=\"euclidean\"))\n",
    "print(best_match(\"How old is Abraham Lincoln?\", method=\"prodscal\"))\n",
    "\n",
    "# How has Canada helped UN peacekeeping efforts? \n",
    "\n",
    "print(best_match(\"Did Canada help UN peacekeeping?\", method=\"cosine\"))\n",
    "print(best_match(\"Did Canada help UN peacekeeping?\", method=\"euclidean\"))\n",
    "print(best_match(\"Did Canada help UN peacekeeping?\", method=\"prodscal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Input de la User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"Intrebare:\")\n",
    "    \n",
    "    if user_input.lower() in [\"exit\"]:\n",
    "        break\n",
    "\n",
    "    answer = best_match(user_input)\n",
    "    print(answer[\"Answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
